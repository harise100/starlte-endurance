From mtosatti@redhat.com  Thu Sep  3 14:36:47 2009
From: Marcelo Tosatti <mtosatti@redhat.com>
Date: Thu,  6 Aug 2009 14:39:55 -0300
Subject: KVM: MMU: increase per-vcpu rmap cache alloc size
To: stable@kernel.org
Cc: Marcelo Tosatti <mtosatti@redhat.com>, avi@redhat.com
Message-ID: <1249580407-21883-16-git-send-email-mtosatti@redhat.com>


From: Marcelo Tosatti <mtosatti@redhat.com>

(cherry picked from commit c41ef344de212bd918f7765af21b5008628c03e0)

The page fault path can use two rmap_desc structures, if:

- walk_addr's dirty pte update allocates one rmap_desc.
- mmu_lock is dropped, sptes are zapped resulting in rmap_desc being
  freed.
- fetch->mmu_set_spte allocates another rmap_desc.

Increase to 4 for safety.

Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
Signed-off-by: Avi Kivity <avi@redhat.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>
---
 arch/x86/kvm/mmu.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -298,7 +298,7 @@ static int mmu_topup_memory_caches(struc
 	if (r)
 		goto out;
 	r = mmu_topup_memory_cache(&vcpu->arch.mmu_rmap_desc_cache,
-				   rmap_desc_cache, 1);
+				   rmap_desc_cache, 4);
 	if (r)
 		goto out;
 	r = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);
